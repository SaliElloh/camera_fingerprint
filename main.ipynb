{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0719e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "import bm3d\n",
    "from skimage import io, img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for denoising:\n",
    "from skimage.restoration import denoise_wavelet, estimate_sigma\n",
    "from skimage import data, img_as_float\n",
    "from skimage.util import random_noise\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4167ebe6",
   "metadata": {},
   "source": [
    "work onn VISION dataset:\n",
    "work on DO1 camera only\n",
    "\n",
    "CALCULATING THE PRNU FOR A SPECIFIC CAMERA:\n",
    "1. get all flat images in one folder - Sali\n",
    "2. convert flat images to grayscale - Sali\n",
    "3. denoising (using wavelet) - Aditya \n",
    "4. calculate noise residual (original - denoise image) for each image in the flat images - Aditya\n",
    "5. calculate: equation in image \"eq1' - Sali\n",
    "6. calculate CRLB  in image 'eq2' - Sali\n",
    "\n",
    "7. calculate linear pattern in image 'eq3', this is K which is the PRNU - write the equation in code format - Kavan\n",
    "8. calculate conversion from RGB to grayscale in image 'eq4' or explore other conversion methods - Kavan\n",
    "\n",
    "CALCULATING THE SIMILARITY BETWEEN A CAMERA'S FINGERPRINT AND A NEW TEST IMAGE:\n",
    "work with natural images for camera DO1\n",
    "9. calculate the noise residual (original image - denoised image)  (W2) noise residual for test image - Sri\n",
    "\n",
    "#########################################\n",
    "\n",
    "10. calculate X and Y in equations in img 'eq5'\n",
    "11. Calculate the NCC in img 'eq6'\n",
    "12. calculate the PCE in img 'eq7'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc104c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/Sali/camera_fingerprint/Dresden_Exp/Agfa_DC-504_0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/data/Sali/camera_fingerprint/Dresden_Exp'\n",
    "camera_ls = os.listdir(data_dir)\n",
    "camera_ls = camera_ls[:1]\n",
    "\n",
    "# Create list of all camera directories\n",
    "camera_dirs = [data_dir + '/' + camera for camera in camera_ls ]\n",
    "camera_dirs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401eb2b",
   "metadata": {},
   "source": [
    "### Moving images to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2269b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_output_dir = '/data/Sali/camera_fingerprint/Vision_dataset_organized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5060db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c4775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def move_images_to_folder(camera_dir, output_dir):\n",
    "#     list_of_cameras = [f'D{str(i).zfill(2)}' for i in range(1, 37)]\n",
    "#     subdirs = ['flat', 'nat', 'natFBH', 'natFBL', 'natWA']\n",
    "\n",
    "#     for cam in list_of_cameras:\n",
    "        \n",
    "#         cam_dir = os.path.join(output_dir, cam)\n",
    "#         os.makedirs(cam_dir, exist_ok=True)  \n",
    "#         subdirs = ['flat', 'nat', 'natFBH', 'natFBL', 'natWA']\n",
    "\n",
    "#         for sub in subdirs:\n",
    "#             sub_dir = os.path.join(cam_dir, sub)\n",
    "#             os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "#     for image in os.listdir(camera_dir):\n",
    "#         if image.endswith('.jpg') or image.endswith('.png'):\n",
    "#             image_parts = image.split('_')\n",
    "\n",
    "#             camera_id = image_parts[0]\n",
    "#             subdir = image_parts[2]\n",
    "#             current_img_path = os.path.join(camera_dir, image)\n",
    "#             new_img_path = os.path.join(output_dir, camera_id, subdir, image)\n",
    "\n",
    "#             try:\n",
    "#                 shutil.copy(current_img_path, new_img_path)\n",
    "#             except FileNotFoundError:\n",
    "#                 print(f\"Error: {current_img_path} not found.\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error copying {image}: {e}\")\n",
    "    \n",
    "# move_images_to_folder('/data/Sali/camera_fingerprint/', images_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd220f",
   "metadata": {},
   "source": [
    "### Extracting PRNU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1654fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noise_residual(img):\n",
    "    blur = cv2.GaussianBlur(img, (5,5), 0) #use filter in paper \n",
    "\n",
    "    noise_residual = img  - blur\n",
    "\n",
    "    return noise_residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8338de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noise_residual(img):\n",
    "    # wavelet denoising\n",
    "    blur = cv2.GaussianBlur(img, (5,5), 0) #use filter in paper \n",
    "\n",
    "    noise_residual = img  - blur\n",
    "\n",
    "    return noise_residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e405c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_noise_residual(img_path):\n",
    "    \n",
    "#     print(f'processing img: {img_path}\\n')\n",
    "#     sigma = 30/255\n",
    "\n",
    "#     noisy_image = img_as_float(io.imread(img_path))\n",
    "#     denoised_image = bm3d.bm3d(noisy_image, sigma_psd=sigma)\n",
    "\n",
    "#     noise_residual = noisy_image  - denoised_image\n",
    "\n",
    "#     return noise_residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_CRP(img_paths, camera_dir):\n",
    "    residuals = []\n",
    "    for img_path in img_paths:\n",
    "        train_img_path = os.path.join(camera_dir, img_path)\n",
    "        img = cv2.imread(train_img_path).astype(np.float32)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        noise_residual = extract_noise_residual(img)\n",
    "        residuals.append(noise_residual)\n",
    "\n",
    "    if residuals:\n",
    "\n",
    "        average_residual = np.mean(residuals, axis=0) # change this to match the paper's method \n",
    "        return average_residual\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_CRP(train_paths, camera_dir):\n",
    "#     residuals = []\n",
    "#     train_img_paths = [os.path.join(camera_dir, fname) for fname in train_paths]\n",
    "\n",
    "#     with Pool(cpu_count()) as pool:\n",
    "#         residuals = pool.map(extract_noise_residual, train_img_paths)\n",
    "\n",
    "#     residuals = [res for res in residuals if res is not None]\n",
    "\n",
    "#     if residuals:\n",
    "#         average_residual = np.mean(residuals, axis=0)\n",
    "\n",
    "#         return average_residual\n",
    "    \n",
    "#     else:\n",
    "#         return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d88799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_Correlation(camera_CRP, test_img_PRNU):\n",
    "    numerator = np.sum(camera_CRP * test_img_PRNU)\n",
    "    denominator = np.sqrt(np.sum(camera_CRP**2) * np.sum(test_img_PRNU**2))\n",
    "    return numerator/denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cff72b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (35,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m img_paths \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(camera_dir)[:\u001b[38;5;241m50\u001b[39m]\n\u001b[1;32m      3\u001b[0m train_paths, test_paths \u001b[38;5;241m=\u001b[39m train_test_split(img_paths , test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m CRP \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_CRP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CRP \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno valid training images\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m, in \u001b[0;36mcalculate_CRP\u001b[0;34m(train_paths, camera_dir)\u001b[0m\n\u001b[1;32m      7\u001b[0m     residuals\u001b[38;5;241m.\u001b[39mappend(noise_residual)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m residuals:\n\u001b[0;32m---> 11\u001b[0m     average_residual \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresiduals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# change this to match the paper's method \u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_residual\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/data/Sali/camera_fingerprint/camera_fingerprint/lib64/python3.9/site-packages/numpy/_core/fromnumeric.py:3596\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3593\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3594\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3597\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/Sali/camera_fingerprint/camera_fingerprint/lib64/python3.9/site-packages/numpy/_core/_methods.py:111\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 111\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (35,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "for camera_dir in camera_dirs:\n",
    "    img_paths = os.listdir(camera_dir)[:50]\n",
    "    # train_paths, test_paths = train_test_split(img_paths , test_size=0.3, random_state=42)\n",
    "    CRP = calculate_CRP(img_paths, camera_dir)\n",
    "\n",
    "    if CRP is None:\n",
    "        print('no valid training images')\n",
    "        continue\n",
    "\n",
    "    # for test_img in test_paths:\n",
    "    #     test_img_path = os.path.join(camera_dir, test_img)\n",
    "    #     img = cv2.imread(test_img_path).astype(np.float32)\n",
    "    #     if img is None:\n",
    "    #         continue\n",
    "\n",
    "        \n",
    "    #     test_residual = extract_noise_residual(img)\n",
    "    #     similarity = Cross_Correlation(CRP, test_residual)\n",
    "        \n",
    "    #     print(f'{test_img}, Similarity: {similarity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosscorr_2d(k1: np.ndarray, k2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    PRNU 2D cross-correlation\n",
    "    :param k1: 2D matrix of size (h1,w1)\n",
    "    :param k2: 2D matrix of size (h2,w2)\n",
    "    :return: 2D matrix of size (max(h1,h2),max(w1,w2))\n",
    "    \"\"\"\n",
    "    assert (k1.ndim == 2)\n",
    "    assert (k2.ndim == 2)\n",
    "\n",
    "    max_height = max(k1.shape[0], k2.shape[0])\n",
    "    max_width = max(k1.shape[1], k2.shape[1])\n",
    "\n",
    "    k1 -= k1.flatten().mean()\n",
    "    k2 -= k2.flatten().mean()\n",
    "\n",
    "    k1 = np.pad(k1, [(0, max_height - k1.shape[0]), (0, max_width - k1.shape[1])], mode='constant', constant_values=0)\n",
    "    k2 = np.pad(k2, [(0, max_height - k2.shape[0]), (0, max_width - k2.shape[1])], mode='constant', constant_values=0)\n",
    "\n",
    "    k1_fft = fft2(k1, )\n",
    "    k2_fft = fft2(np.rot90(k2, 2), )\n",
    "\n",
    "    return np.real(ifft2(k1_fft * k2_fft)).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def7efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pce(cc: np.ndarray, gt: np.ndarray, ) -> dict:\n",
    "    \"\"\"\n",
    "    Compute statistics\n",
    "    :param cc: cross-correlation or normalized cross-correlation matrix\n",
    "    :param gt: boolean multidimensional array representing groundtruth\n",
    "    :return: statistics dictionary\n",
    "    \"\"\"\n",
    "    assert (cc.shape == gt.shape)\n",
    "    assert (gt.dtype == np.bool)\n",
    "\n",
    "    assert (cc.shape == gt.shape)\n",
    "    assert (gt.dtype == np.bool)\n",
    "\n",
    "    fpr, tpr, th = roc_curve(gt.flatten(), cc.flatten())\n",
    "    auc_score = auc(fpr, tpr)\n",
    "\n",
    "    # EER\n",
    "    eer_idx = np.argmin((fpr - (1 - tpr)) ** 2, axis=0)\n",
    "    eer = float(fpr[eer_idx])\n",
    "\n",
    "    outdict = {\n",
    "        'tpr': tpr,\n",
    "        'fpr': fpr,\n",
    "        'th': th,\n",
    "        'auc': auc_score,\n",
    "        'eer': eer,\n",
    "    }\n",
    "\n",
    "    return outdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_fixed_pattern_noise(K_hat: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Removes fixed pattern noise (row and column) from a 2D matrix.\n",
    "    \n",
    "    Equation (eq3.png) implementation:\n",
    "    1. r_i = 1/n * sum_{j=1}^{n} K_hat[i,j]\n",
    "    2. K'[i,j] = K_hat[i,j] - r_i\n",
    "    3. c_j = 1/m * sum_{i=1}^{m} K'[i,j]\n",
    "    4. K''[i,j] = K'[i,j] - c_j\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Getting the dimensions of the input matrix K_hat\n",
    "    m, n = K_hat.shape\n",
    "\n",
    "    K_prime = np.copy(K_hat)\n",
    "    K_double_prime = np.copy(K_prime)\n",
    "\n",
    "    # r_i = 1/n * sum_{j=1}^{n} K_hat[i,j]\n",
    "    \n",
    "    r_i = np.mean(K_hat, axis=1)\n",
    "\n",
    "    # Subtracting r_i from each row of K_hat to get K_prime.\n",
    "    # K'[i,j] = K_hat[i,j] - r_i\n",
    "\n",
    "    K_prime = K_hat - r_i[:, np.newaxis]\n",
    "\n",
    "    #Finding the mean of each column in K_prime\n",
    "    # c_j = 1/m * sum_{i=1}^{m} K'[i,j]\n",
    "    \n",
    "    c_j = np.mean(K_prime, axis=0)\n",
    "\n",
    "    # Subtract c_j from each column of K_prime to get K_double_prime.\n",
    "    # K''[i,j] = K'[i,j] - c_j\n",
    "    \n",
    "    K_double_prime = K_prime - c_j\n",
    "\n",
    "    return K_double_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547de1f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4290831171.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    https://github.com/samuelebortolotti/neural-prnu-extractor #code to replicate\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://github.com/samuelebortolotti/neural-prnu-extractor #code to replicate\n",
    "https://github.com/ocrim1996/prnu-python?tab=readme-ov-file\n",
    "https://ieeexplore.ieee.org/document/7791195 # image alignment \n",
    "https://ieeexplore.ieee.org/document/7791195 # paper that talks about denoising filter\n",
    "https://paperswithcode.com/sota/image-denoising-on-sidd # papers with code\n",
    "https://www.reddit.com/r/AirlinerAbduction2014/comments/1fnxy5o/photo_response_nonuniformity_prnu_authentication/#:~:text=Extracting%20the%20PRNU%20requires%20denoising,is%20compared%20to%20the%20CRP. # reddit page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CamPRNU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
