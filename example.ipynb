{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f9ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.Functions as Fu\n",
    "import src.Filter as Ft\n",
    "import src.getFingerprint as gF\n",
    "import src.maindir as md\n",
    "import src.extraUtils as eu\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcce371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   32   *\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# extracting Fingerprint from same size images in a path\n",
    "data_dir = '/data/Sali/camera_fingerprint/CameraFingerprint/D01/flat'\n",
    "Images = [os.path.join(data_dir, fname) for fname in os.listdir(data_dir) if fname.endswith('.jpg')]\n",
    "\n",
    "RP,_,_ = gF.getFingerprint(Images)\n",
    "RP = Fu.rgb2gray1(RP)\n",
    "sigmaRP = np.std(RP)\n",
    "Fingerprint = Fu.WienerInDFT(RP, sigmaRP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(Fingerprint) # PRNU\n",
    "\n",
    "# To save RP in a '.mat' file:\n",
    "import scipy.io as sio\n",
    "sio.savemat('Fingerprint.mat', {'RP': RP, 'sigmaRP': sigmaRP, 'Fingerprint': Fingerprint})\n",
    "\n",
    "imx = '/data/Sali/camera_fingerprint/CameraFingerprint/D01/nat/D01_I_nat_0002.jpg'\n",
    "Noisex = Ft.NoiseExtractFromImage(imx, sigma=2.)\n",
    "Noisex = Fu.WienerInDFT(Noisex, np.std(Noisex))\n",
    "\n",
    "# The optimal detector (see publication \"Large Scale Test of Sensor Fingerprint Camera Identification\")\n",
    "Ix = cv.cvtColor(cv.imread(imx),# image in BGR format\n",
    "                 cv.COLOR_BGR2GRAY)\n",
    "\n",
    "C = Fu.crosscorr(Noisex,np.multiply(Ix, Fingerprint))\n",
    "print(C)\n",
    "det, det0 = md.PCE(C)\n",
    "for key in det.keys(): print(\"{0}: {1}\".format(key, det[key]))\n",
    "eu.mesh(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find PCE for each camera, and plot the peak correlation energy \n",
    "# randomly pick images, and determine what camera it belongs to\n",
    "# determne the PCE threshold that determines whether a camera belongs to a certain camera or not\n",
    "# taking those images and compress them, (post processing), resizing cropping, color correction\n",
    "# create laundered dataset for images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27654d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# found PRNU for D01 camera using flat images\n",
    "# found PCE value for a nat image in D01 dataset\n",
    "\n",
    "# find PRNU for all cameras using flat images (if you have 35 cameras, we need to find 35 PRNU for VISION dataset))\n",
    "# for each test images in nat dataset, find the PCE with each camera\n",
    "# find the camera with the highest PCE value, and determine if it is a match or not, by plotting all the PCE values assoctiated with each camera\n",
    "# if the PCE value is above a certain threshold, then it is a match  (do this for multiple images)\n",
    "\n",
    "\n",
    "# based on PCE plots of different test images, determine the threshold for PCE value \n",
    "# find the threshold for each camera \n",
    "\n",
    "# create a laundered dataset for images, by postprocessing natural images using techniques like scaling, compressing, resizing, cropping, color correction, and measuring the PCE value after each step\n",
    "\n",
    "\n",
    "# take 4 datasets from VISION dataset and 4 datasets from dresden dataset\n",
    "# for Dresden:\n",
    "    # 1. split the dataset into 2 parts, 1 for training and 1 for testing (50%, 50%)\n",
    "    # 2. calculate PRNU for training images (store the PRNU for future camparison)\n",
    "    # 3. find PCE for test images by comparing it with the stored PRNU\n",
    "    # 4. plot the PCE values for each camera\n",
    "\n",
    "    # 5 decide threshold for each camera by averaging the PCE values for each camera\n",
    "\n",
    "# for VISION:\n",
    "    # 1. calculate PRNU for flat images (store the PRNU for future camparison)\n",
    "    # 2. find PCE for nat images by comparing it with the stored PRNU\n",
    "    # 3. plot the PCE values for each camera\n",
    "    # 4. decide threshold for each camera by averaging the PCE values for each camera\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce98bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 2560)\n"
     ]
    }
   ],
   "source": [
    "print(Fingerprint.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camera_fingerprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
